apiVersion: v1
kind: ConfigMap
metadata:
  name: llamastack-run-config
  namespace: llamastack
data:
  run.yaml: |
    version: '2'
    image_name: starter
    providers:
      inference:
        - provider_id: azure-openai
          provider_type: remote::openai
          config:
            api_key: ${env.AZURE_API_KEY}
            openai_compatible_api_base: ${env.AZURE_API_BASE}
      memory:
        - provider_id: faiss
          provider_type: inline::faiss
          config:
            kvstore:
              type: sqlite
              db_path: /root/.llama/sqlite/faiss_store.db
      agents:
        - provider_id: meta-reference
          provider_type: inline::meta-reference
          config:
            persistence_store:
              type: sqlite
              db_path: /root/.llama/sqlite/agents_store.db
      telemetry:
        - provider_id: meta-reference
          provider_type: inline::meta-reference
          config:
            sqlite_db_path: /root/.llama/sqlite/trace_store.db
      safety: []

    models:
      - model_id: llamastack
        provider_id: azure-openai
        provider_resource_id: llamastack
        model_type: llm
        metadata: {}

    shields: []
    memory_banks: []
    datasets: []
    scoring_fns: []
    eval_tasks: []
    tool_groups: []