apiVersion: apps/v1
kind: Deployment
metadata:
  name: llamastack
  namespace: llamastack
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llamastack
  template:
    metadata:
      labels:
        app: llamastack
    spec:
      containers:
        # Sidecar Ollama
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - containerPort: 11434
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "1Gi"
          readinessProbe:
            httpGet:
              path: /api/models
              port: 11434
            initialDelaySeconds: 10
            periodSeconds: 5
        # Llama Stack
        - name: llamastack
          image: llamastack/distribution-starter:latest
          ports:
            - containerPort: 8321
          env:
            - name: INFERENCE_MODEL
              value: "ollama/llama3.2:3b"
            - name: OLLAMA_URL
              value: "http://localhost:11434"
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "1Gi"
          readinessProbe:
            httpGet:
              path: /api/health
              port: 8321
            initialDelaySeconds: 15
            periodSeconds: 10
          volumeMounts:
            - name: llama-data
              mountPath: /root/.llama
      volumes:
        - name: llama-data
          emptyDir: {}
      imagePullSecrets:
        - name: ghcr-secret
