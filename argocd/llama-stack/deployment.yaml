apiVersion: apps/v1
kind: Deployment
metadata:
  name: llamastack
  namespace: llamastack
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llamastack
  template:
    metadata:
      labels:
        app: llamastack
    spec:
      containers:
        # Sidecar do Ollama
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - containerPort: 11434
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "1Gi"
        # Container LlamaStack
        - name: llamastack
          image: llamastack/distribution-ollama:latest
          ports:
            - containerPort: 5001
          env:
            - name: INFERENCE_MODEL
              value: "llama3.2:3b"
            - name: OLLAMA_URL
              value: "http://localhost:11434"
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "1Gi"