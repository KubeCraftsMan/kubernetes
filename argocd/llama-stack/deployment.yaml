apiVersion: apps/v1
kind: Deployment
metadata:
  name: llamastack
  namespace: llamastack
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llamastack
  template:
    metadata:
      labels:
        app: llamastack
    spec:
      containers:
        # Sidecar Ollama
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - containerPort: 11434
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
          readinessProbe:
            httpGet:
              path: /api/models
              port: 11434
            initialDelaySeconds: 10
            periodSeconds: 5
          startupProbe:
            httpGet:
              path: /api/models
              port: 11434
            failureThreshold: 30
            periodSeconds: 5

        # Llama Stack
        - name: llamastack
          image: llamastack/distribution-starter:latest
          ports:
            - containerPort: 8321
          env:
            - name: OLLAMA_URL
              value: "http://localhost:11434"
            - name: INFERENCE_MODEL
              value: "ollama/llama3.2:3b"
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
          readinessProbe:
            httpGet:
              path: /api/ps
              port: 8321
            initialDelaySeconds: 20
            periodSeconds: 5
          startupProbe:
            httpGet:
              path: /api/ps
              port: 8321
            failureThreshold: 30
            periodSeconds: 5
